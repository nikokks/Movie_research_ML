# Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks


ABSTRACT

BERT et RoBERTa ont établi une nouvelle performance de pointe sur les tâches de régression de paires de phrases comme la similarité textuelle sémantique (STS). Cependant, cela nécessite que les deux phrases soient introduites dans le réseau, ce qui entraîne une surcharge de calcul massive : trouver la paire la plus similaire dans une collection de 10 000 phrases nécessite environ 50 millions de calculs d'inférence (~ 65 heures) avec BERT. La construction de BERT le rend inadapté à la recherche de similarité sémantique ainsi qu'aux tâches non supervisées comme le clustering.
Dans cette publication, nous présentons Sentence-BERT (SBERT), une modification du réseau BERT pré-entraîné qui utilise des structures de réseau siamois et triplet pour dériver des plongements de phrases sémantiquement significatifs qui peuvent être comparés à l'aide de la similitude cosinusoïdale. Cela réduit l'effort pour trouver la paire la plus similaire de 65 heures avec BERT / RoBERTa à environ 5 secondes avec SBERT, tout en maintenant la précision de BERT. Nous évaluons SBERT et SRoBERTa sur des tâches STS courantes et des tâches d'apprentissage de transfert, où elles surpassent les autres méthodes d'intégration de phrases de pointe.




INTRODUCTION

Dans cette publication, nous présentons Sentence-BERT (SBERT), une modification du réseau BERT utilisant des réseaux siamois et triplet qui est capable de dériver des plongements de phrases sémantiquement significatifs 2 . Cela permet au BERT d'être utilisé pour certaines nouvelles tâches, qui jusqu'à présent n'étaient pas applicables au BERT. Ces tâches incluent la comparaison de similarité sémantique à grande échelle, le regroupement et la récupération d'informations via la recherche sémantique. BERT a établi de nouvelles performances de pointe sur diverses tâches de classification de phrases et de régression de paires de phrases. BERT utilise un encodeur croisé : deux phrases sont transmises au réseau de transformateurs et la valeur cible est prédite. Cependant, cette configuration n'est pas adaptée à diverses tâches de régression de paires en raison du trop grand nombre de combinaisons possibles. Trouver dans une collection de n = 10 000 phrases la paire avec la plus grande similarité nécessite avec BERT n·(n−1)/2 = 49 995 000 calculs d'inférence.
Sur un GPU V100 moderne, cela nécessite environ 65 heures. Similaire, trouver laquelle des plus de 40 millions de questions existantes de Quora est la plus similaire pour une nouvelle question pourrait être modélisée comme une comparaison par paire avec BERT, cependant, répondre à une seule requête nécessiterait plus de 50 heures.
Une méthode courante pour traiter le clustering et la recherche sémantique consiste à mapper chaque phrase à un espace vectoriel de telle sorte que les phrases sémantiquement similaires soient proches. Les chercheurs ont commencé à saisir des phrases individuelles dans BERT et à dériver des intégrations de phrases de taille fixe. L'approche la plus couramment utilisée consiste à faire la moyenne de la couche de sortie BERT (appelée intégrations BERT) ou en utilisant la sortie du premier jeton (le jeton [CLS]). Comme nous le montrerons, cette pratique courante produit des intégrations de phrases plutôt mauvaises, souvent pires que la moyenne des intégrations de GloVe (Pennington et al., 2014).
Pour pallier ce problème, nous avons développé SBERT.
L'architecture de réseau siamois permet de dériver des vecteurs de taille fixe pour les phrases d'entrée. En utilisant une mesure de similarité comme la similitude en cosinus ou la distance Manhattan / Euclidienne, des phrases sémantiquement similaires peuvent être trouvées. Ces mesures de similarité peuvent être exécutées de manière extrêmement efficace sur du matériel moderne, permettant à SBERT d'être utilisé pour la recherche de similarité sémantique ainsi que pour le clustering. La complexité pour trouver la paire de phrases la plus similaire dans une collection de 10 000 phrases est réduite de 65 heures avec BERT au calcul de 10 000 intégrations de phrases (~ 5 secondes avec SBERT) et au calcul de la similitude de cosinus (~ 0,01 seconde). En utilisant des structures d'index optimisées, la recherche de la question Quora la plus similaire peut être réduite de 50 heures à quelques millisecondes (Johnson et al., 2017).
Nous ajustons SBERT sur les données NLI, ce qui crée des intégrations de phrases qui surpassent considérablement les autres méthodes d'intégration de phrases de pointe comme InferSent (Conneau et al., 2017) et Universal Sentence Encoder (Cer et al., 2018). Sur sept tâches de similarité textuelle sémantique (STS), SBERT obtient une amélioration de 11,7 points par rapport à InferSent et de 5,5 points par rapport à Universal Sentence Encoder. Sur SentEval (Conneau et Kiela, 2018), une boîte à outils d'évaluation pour les inclusions de phrases, nous obtenons une amélioration de 2,1 et 2,6 points, respectivement.
SBERT peut être adapté à une tâche spécifique. Il définit de nouvelles performances de pointe sur un ensemble de données de similarité d'arguments difficiles (Misra et al., 2016) et sur un ensemble de données triplet pour distinguer les phrases de différentes sections d'un article Wikipedia (Dor et al., 2018).
L'article est structuré de la manière suivante : la section 3 présente SBERT, la section 4 évalue SBERT sur les tâches STS courantes et sur le corpus difficile de la similarité des facettes d'arguments (AFS) (Misra et al., 2016). La section 5 évalue SBERT sur SentEval. Dans la section 6, nous effectuons une étude d'ablation pour tester certains aspects de la conception de SBERT. Dans la section 7, nous comparons l'efficacité de calcul des incorporations de phrases SBERT par rapport à d'autres méthodes d'incorporation de phrases de pointe.
